# Web Scraping

## Scraping Static vs Dynamic

**Rendering of Content:**

- *Static Websites:* Content is fixed and directly available in the HTML source code.
- *Dynamic Websites:* Content is often loaded dynamically using JavaScript, making it necessary to execute JavaScript to fetch and render the data.

**Data Accessibility:**

- *Static Websites:* Data is readily available in the HTML source code, making extraction relatively straightforward.
- *Dynamic Websites:* Data may be loaded asynchronously or after the initial HTML load, requiring additional steps to retrieve the dynamically generated content.

**Interaction and User Input:**

- *Static Websites:* Interaction is limited to basic HTML forms and links.
- *Dynamic Websites:* Interaction often involves more complex actions like button clicks, AJAX requests, and handling dynamic content changes.

## Don't Get Blocked

*Use of Proxies:*

Rotate IP addresses by using a pool of proxies to distribute requests across different servers, reducing the chance of being detected and blocked.

*Rate Limiting:*

Mimic human-like behavior by introducing delays between requests (throttling). This prevents overwhelming the server with a high volume of requests and reduces the likelihood of being flagged as a bot.

*User-Agent Rotation:*

Change the User-Agent header in your HTTP requests to simulate different browsers and devices. This helps avoid detection based on a consistent User-Agent associated with a bot.

**Playwright** is a tool for browser automation, similar to *Puppeteer*, but it supports multiple browsers (Chrome, Firefox, WebKit). It allows for headless browsing, navigation, and interaction with web pages.

- Example: Suppose you need to scrape a website that heavily relies on JavaScript to load and display data. Playwright can be beneficial in this scenario as it provides a headful browser environment, allowing you to interact with the page just as a user would. This includes clicking buttons, filling forms, and handling dynamic content. The ability to interact with the page dynamically is crucial in cases where a traditional static scraper might fail.

**XPath (XML Path Language):**

*XPath* is a query language used to navigate XML documents, including HTML. In web scraping, XPath is often employed to locate and select specific elements on a webpage.

Example XPath Expression:

- Suppose you want to select the title of a blog post on a webpage. The XPath expression to select the title might look like this:

```python
//h1[@class='blog-post-title']
```

//: Selects nodes in the document from the current node that match the selection, regardless of their location.

h1: Selects the *h1 element.*

[@class='blog-post-title']: Filters the selection based on the class attribute being equal to 'blog-post-title'.

This XPath expression targets an *h1 element* with the specified class, allowing you to extract the title of the blog post from the HTML structure of the webpage.

### Sources:

[Scape a Dynamic Website](https://scrapingant.com/blog/scrape-dynamic-website-with-python)

[Scape Without Getting Blocked](https://www.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/)

Chat GPT