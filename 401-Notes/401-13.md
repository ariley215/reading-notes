# Linear Regressions

**Linear Regression** - Can be thought of as finding the straight line that best fits a set of scattered data points. Then project that line to predict new data points.

- It's a supervised learning algorithm commonly employed for tasks like predicting house prices, sales, or any continuous numeric output.

Linear Regression Implementation:

1. Import Libraries

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
```

2. Load and Prepare Data:

```python
# Assuming 'df' is your DataFrame
X = df[['feature1', 'feature2', ...]]
y = df['target']
```

3. Split Dataset:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

4. Create and Train the Model:

```python
model = LinearRegression()
model.fit(X_train, y_train)
```

5. Make Prediction:

```python
predictions = model.predict(X_test)
```

6. Evaluate Model Performance

```python
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))
```

7. Visualize

```python
import matplotlib.pyplot as plt

plt.scatter(y_test, predictions)
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.show()
```

Purpose of splitting the dataset into train and test sets:

- Crucial for assessing the model's ability to generalize to new, unseen data.
- It helps prevent *overfitting*: where the model performs well on the training data but poorly on new data.
- Provides a more realistic measure of its performance in real-world scenarios.


## Sources

[Run a Linear Regression](https://www.activestate.com/resources/quick-reads/how-to-run-linear-regressions-in-python-scikit-learn/)

[Linear Regression](https://realpython.com/linear-regression-in-python/)
ChatGPT
